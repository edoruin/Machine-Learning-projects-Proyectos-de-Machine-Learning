{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91714,"databundleVersionId":11251744,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/edwinagustn/binary-prediction-competition?scriptVersionId=230623124\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:13:54.069948Z","iopub.execute_input":"2025-03-30T18:13:54.070389Z","iopub.status.idle":"2025-03-30T18:13:54.080368Z","shell.execute_reply.started":"2025-03-30T18:13:54.07032Z","shell.execute_reply":"2025-03-30T18:13:54.079214Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Overview","metadata":{}},{"cell_type":"code","source":"#Estyle\nimport matplotlib.pyplot as plt \nimport seaborn as sns \nfrom tqdm import tqdm\n\n\n#Models\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.feature_selection import RFECV\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\n#metrics\nfrom sklearn.metrics import roc_curve, roc_auc_score, auc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:13:54.081744Z","iopub.execute_input":"2025-03-30T18:13:54.082122Z","iopub.status.idle":"2025-03-30T18:13:54.097332Z","shell.execute_reply.started":"2025-03-30T18:13:54.082077Z","shell.execute_reply":"2025-03-30T18:13:54.096023Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nRealized by Edwin Agustin\n2025-3-25\n\nClassify as: academic project\n\"\"\"\n\ntrain = pd.read_csv('/kaggle/input/playground-series-s5e3/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s5e3/test.csv')\n\nprint(f\"train_info:\\n{train.info()}\\n\\n{train.describe()}\")\nprint(f\"test_info:\\n{test.info()}\\n\\n{test.describe()}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:13:54.099256Z","iopub.execute_input":"2025-03-30T18:13:54.099688Z","iopub.status.idle":"2025-03-30T18:13:54.192207Z","shell.execute_reply.started":"2025-03-30T18:13:54.099642Z","shell.execute_reply":"2025-03-30T18:13:54.19112Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.fillna(test.mean(),inplace=True)\ntest.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:13:54.19358Z","iopub.execute_input":"2025-03-30T18:13:54.19403Z","iopub.status.idle":"2025-03-30T18:13:54.210902Z","shell.execute_reply.started":"2025-03-30T18:13:54.193991Z","shell.execute_reply":"2025-03-30T18:13:54.209786Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Target variable\nTarget_Classes = train['rainfall'].value_counts()\n\n#do groupby\nplt.figure(figsize = (20,10))\nTarget_Classes.plot(kind = 'bar',color =['blue','orange'])\nplt.title('Target Clases Distribution')\nplt.xlabel(\"Category\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=0)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:13:54.211888Z","iopub.execute_input":"2025-03-30T18:13:54.212143Z","iopub.status.idle":"2025-03-30T18:13:54.606618Z","shell.execute_reply.started":"2025-03-30T18:13:54.212121Z","shell.execute_reply":"2025-03-30T18:13:54.605565Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature Selection","metadata":{}},{"cell_type":"code","source":"#corr plot \nplt.figure(figsize=(10,6))\nsns.heatmap(train.corr(), annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n\n# T√≠tulo del gr√°fico\nplt.title(\"Heatmap - Pearson Correlation\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:13:54.608882Z","iopub.execute_input":"2025-03-30T18:13:54.609174Z","iopub.status.idle":"2025-03-30T18:13:55.292282Z","shell.execute_reply.started":"2025-03-30T18:13:54.609149Z","shell.execute_reply":"2025-03-30T18:13:55.291068Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#preparing features \nX = train.drop(columns=['rainfall','id'])  \ny = train['rainfall'].drop(columns =['id'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:13:55.293584Z","iopub.execute_input":"2025-03-30T18:13:55.293891Z","iopub.status.idle":"2025-03-30T18:13:55.299666Z","shell.execute_reply.started":"2025-03-30T18:13:55.293866Z","shell.execute_reply":"2025-03-30T18:13:55.298437Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n#Models Diccionary \nmodels = {\n    'XGBClassifier': XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1),\n    'CatBoost': CatBoostClassifier(iterations=100, depth=3, learning_rate=0.1, verbose=0),\n    'RandomForest': RandomForestClassifier(n_estimators=100, max_depth=3)\n}\n\n\n   \nclass Create_and_test:\n    \"\"\"\n    DESCRIPTION:\n    This class trains models, selects features using Recursive Feature Elimination (RFE),\n    and evaluates model performance using cross-validation.\n\n    PARAMETERS:\n    - `X`: DataFrame, feature matrix.\n    - `y`: Series or array, target variable.\n    - `model_name`: str, name of the model to use from `models`.\n    - `cv_folds`: int, number of folds for cross-validation (default: 5).\n\n    METHODS:\n    - `show_results()`: Prints the number of selected features and cross-validation score.\n    - `plot_model()`: Evaluates the trained model using plots and descriptive statistics \n    \"\"\"\n\n    def __init__(self, X, y, model_name, cv_folds=5):\n        \"\"\"\n        Initializes the model, applies Recursive Feature Elimination (RFE) with cross-validation, \n        and selects the optimal features.\n        \n        Parameters:\n        - `X`: Feature matrix (DataFrame).\n        - `y`: Target variable (Series or array).\n        - `model_name`: Model name (string), must be in `models` dictionary.\n        - `cv_folds`: Number of cross-validation folds (default: 5).\n\n        Return:\n        - model name\n        - the optimal features\n        - the name of these features\n        - the mean by cros validation AUC_ROC metric and general\n        \n        \n        \"\"\"\n        self.X = X\n        self.y = y\n        self.model_name = model_name \n        self.model = models[model_name]  # Model selection\n        self.test  = test\n        \n        # Cros-validation stratified\n        cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n    \n        # RFE with cv\n        with tqdm(desc=f\"Selecting features with {model_name}...\"):\n            self.selector = RFECV(self.model, step=1, cv=cv, scoring='roc_auc', n_jobs=-1)\n            self.selector.fit(X, y)\n        \n        # Results from cros-validation\n        self.optimal_features = self.selector.n_features_\n        self.selected_features = X.columns[self.selector.support_].tolist\n        self.all_results = self.selector.cv_results_['mean_test_score'] #extract the mean of cv by model\n        self.mean_score = np.mean(self.selector.cv_results_[\"mean_test_score\"]) #extract the mean of all_results variable\n        \n    def show_results(self):\n        \"\"\"\n        Displays the results of the Recursive Feature Elimination process.\n\n        Prints:\n        - The optimal number of selected features.\n        - The names of the selected features.\n        - The average cross-validation accuracy score.\n        \"\"\"\n        print(f\"\\nüîπ Model: {self.model_name}\")\n        print(f\"üìå Optimal number of features: {self.optimal_features}\")\n        print(f\"‚úÖ Selected features: {self.selected_features}\")\n        print(f'‚öôÔ∏è Results: {self.all_results}')\n        print(f\"üéØ ROC_AUC_MEAN_CV: {self.mean_score:.4f}\")\n        \n    def testing_model(self):\n        \"\"\"\n        Display analysis of the model's ROC-AUC score using selected features.\n        \"\"\"\n\n        # Conditional features\n        if self.model_name == 'XGBClassifier_F':\n            self.X = train[['day', 'pressure', 'maxtemp', 'temparature', 'mintemp',\n                            'dewpoint', 'humidity', 'cloud', 'sunshine', 'winddirection',\n                            'windspeed']]\n            self.y = train['rainfall'] \n        \n        elif self.model_name == 'CatBoost_M':\n            self.X = train[['pressure', 'maxtemp', 'mintemp', 'dewpoint', 'humidity', 'cloud',\n                            'sunshine', 'windspeed']]\n            self.y = train['rainfall']  \n        \n        else:\n            self.X = train[['temparature', 'dewpoint', 'humidity', 'cloud', 'sunshine']]\n            self.y = train['rainfall']  \n\n        \n        # Splitting data into training and testing sets\n        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=42)\n        \n        # Train the selected model with the RFE-selected features\n        model = self.model\n        model.fit(X_train, y_train)\n    \n        # Make predictions and calculate ROC-AUC score\n        y_probs = model.predict_proba(X_test)[:, 1]  # Get probabilities for class 1\n        \n        roc_auc = roc_auc_score(y_test, y_probs)\n\n        \n\n        print(f\"‚öôÔ∏è {self.model_name} ROC-AUC on Test Set : {roc_auc:.4f}\") #showing results\n        print(f'üìà Plot of ROC_AUC of {self.model_name}: ')\n        \n        #Plotting ROC_AUC\n        fpr, tpr, thresholds = roc_curve(y_test, y_probs) \n        roc_auc = auc(fpr, tpr)\n        plt.figure()\n        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('Receiver Operating Characteristic')\n        plt.legend(loc=\"lower right\")\n        plt.show()\n        \n    def submission(self):\n        \n        test_features = self.test[self.X.columns]\n        \n        #Models training\n        predictions = self.model.predict_proba(test_features)[:, 1]\n        predictions = np.round(predictions, 1) \n        \n        # Create submission file\n        submission_df = pd.DataFrame({\"id\": self.test['id'], \"rainfall\": predictions})\n        submission_df.to_csv('submission.csv', index=False)\n        print(submission_df.head(10))\n                ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:13:55.301041Z","iopub.execute_input":"2025-03-30T18:13:55.301427Z","iopub.status.idle":"2025-03-30T18:13:55.322777Z","shell.execute_reply.started":"2025-03-30T18:13:55.3014Z","shell.execute_reply":"2025-03-30T18:13:55.321625Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Training Models\nXGBClassifier= Create_and_test(X,y,'XGBClassifier')\nCatBoost = Create_and_test(X,y,'CatBoost')\nRandomForest = Create_and_test(X,y,'RandomForest')\n\n#show results\nXGBClassifier.show_results()\nCatBoost.show_results()\nRandomForest.show_results()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:13:55.323973Z","iopub.execute_input":"2025-03-30T18:13:55.324383Z","iopub.status.idle":"2025-03-30T18:14:07.807651Z","shell.execute_reply.started":"2025-03-30T18:13:55.324342Z","shell.execute_reply":"2025-03-30T18:14:07.80641Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# testing Model","metadata":{}},{"cell_type":"code","source":"#Testing models\nXGBClassifier.testing_model()\nCatBoost.testing_model()\nRandomForest.testing_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:14:07.80845Z","iopub.execute_input":"2025-03-30T18:14:07.808849Z","iopub.status.idle":"2025-03-30T18:14:08.720711Z","shell.execute_reply.started":"2025-03-30T18:14:07.808823Z","shell.execute_reply":"2025-03-30T18:14:08.71961Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  Submission ","metadata":{}},{"cell_type":"code","source":"CatBoost.submission()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T18:14:08.721662Z","iopub.execute_input":"2025-03-30T18:14:08.721929Z","iopub.status.idle":"2025-03-30T18:14:08.733585Z","shell.execute_reply.started":"2025-03-30T18:14:08.721906Z","shell.execute_reply":"2025-03-30T18:14:08.732584Z"}},"outputs":[],"execution_count":null}]}